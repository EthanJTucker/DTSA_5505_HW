{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a14a6c2c2b245d45b367756d7fe5f7d",
     "grade": false,
     "grade_id": "cell-6ce5cece863df8e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Homework 3 - Clustering\n",
    "***\n",
    "**Name**: $<$insert name here$>$ \n",
    "***\n",
    "\n",
    "Remember that you are encouraged to discuss the problems with your instructors and classmates, but **you must write all code and solutions on your own**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7d8aeda72f4dd210360cbdc224e7dfd",
     "grade": false,
     "grade_id": "cell-5b17602a9843d8ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The rules to be followed for the assignment are:\n",
    "\n",
    "- Do **NOT** load additional packages beyond what we've shared in the cells below.\n",
    "- Some problems with code may be autograded.  If we provide a function or class API **do not** change it.\n",
    "- Do not change the location of the data or data directory.  Use only relative paths to access the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb2ce4604fc1011f91f321ba3e5d9ef9",
     "grade": false,
     "grade_id": "cell-f0584d2146b12be0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [10 points] Problem 1 - K Means Clustering\n",
    "***\n",
    "\n",
    "A sample dataset has been provided to you in the './data/sample_dataset_kmeans.pickle' path. The centroids are in './data/sample_centroids_kmeans.pickle' and the sample result is in './data/sample_result_kmeans.pickle' path. You can use these to test your code.\n",
    "\n",
    "Here are the attributes for the dataset. Use this dataset to test your functions.\n",
    "\n",
    "- Dataset should load the points in the form of a list of lists where each list item represents a point in the space. \n",
    "- An example dataset will have the following structure. If there are 3 points in the dataset, this would appear as follows in the list of lists.\n",
    "\n",
    "```python\n",
    "dataset = [\n",
    "    [5,6], \n",
    "    [3,5], \n",
    "    [2,8]\n",
    "]\n",
    "  \n",
    "```\n",
    "\n",
    "Note:\n",
    "- A sample dataset to test your code has been provided in the location \"data/sample_dataset_kmeans.pickle\". Please maintain this as it would be necessary while grading.\n",
    "- Do not change the variable names of the returned values.\n",
    "- After calculating each of those values, assign them to the corresponding value that is being returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {'cluster1': [[23, 96], [29, 99], [30, 64], [12, 68]], 'cluster2': [[46, 33], [82, 20], [57, 51], [25, 9]], 'cluster3': [[26, 21], [25, 42]], 'centroids': [[23.5, 81.75], [52.5, 28.25], [25.5, 31.5]]}, '2': {'cluster1': [[23, 96], [29, 99], [30, 64], [12, 68]], 'cluster2': [[46, 33], [82, 20], [57, 51]], 'cluster3': [[26, 21], [25, 42], [25, 9]], 'centroids': [[23.5, 81.75], [61.666666666666664, 34.666666666666664], [25.333333333333332, 24.0]]}}\n"
     ]
    }
   ],
   "source": [
    "path = \"data/sample_dataset_kmeans.pickle\"\n",
    "path2 = \"./data/sample_centroids_kmeans.pickle\"\n",
    "path3 = './data/sample_result_kmeans.pickle'\n",
    "\n",
    "data_file = open(path, \"rb\")\n",
    "test_dataset = pickle.load(data_file)\n",
    "data_file.close()\n",
    "\n",
    "centroid_file = open(path2, \"rb\")\n",
    "test_centroids = pickle.load(centroid_file)\n",
    "centroid_file.close()\n",
    "\n",
    "result_file = open(path3, \"rb\")\n",
    "results = pickle.load(result_file)\n",
    "result_file.close()\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79ee266c5879de86fc89d344378e6fac",
     "grade": false,
     "grade_id": "cell-fa73c03160fb02d1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def cluster_assignment(centroids, point):\n",
    "    \"\"\"\n",
    "        Helper function for k_means_clustering\n",
    "        input: list of lists centroids [x, y], list point [x, y]. Both float only\n",
    "        output: cluster assignment string\n",
    "    \"\"\"\n",
    "    #Assuming names are \"centroid 1\", \"centroid 2\", and \"centroid 3\" in order:\n",
    "    current_best = (float(\"inf\"), \"error\")\n",
    "    \n",
    "    for i in range(len(centroids)):\n",
    "        centroid = centroids[i]\n",
    "        this_distance = np.sqrt((centroid[0] - point[0])**2 + (centroid[1] - point[1])**2)\n",
    "        if this_distance < current_best[0]:\n",
    "            this_string = \"cluster\" + str(i + 1)\n",
    "            current_best = (this_distance, this_string)\n",
    "    \n",
    "    return(current_best[1])\n",
    "\n",
    "def k_means_clustering(centroids, dataset):\n",
    "\n",
    "#   Description: Perform k means clustering for 2 iterations given as input the dataset and centroids.\n",
    "#   Input:\n",
    "#       1. centroids - A list of lists containing the initial centroids for each cluster. \n",
    "#       2. dataset - A list of lists denoting points in the space.\n",
    "#   Output:\n",
    "#       1. results - A dictionary where the key is iteration number and store the cluster assignments in the \n",
    "#           appropriate clusters. Also, update the centroids list after each iteration.\n",
    "\n",
    "    result = {\n",
    "        '1': { 'cluster1': [], 'cluster2': [], 'cluster3': [], 'centroids': []},\n",
    "        '2': { 'cluster1': [], 'cluster2': [], 'cluster3': [], 'centroids': []}\n",
    "    }\n",
    "    \n",
    "    centroid1, centroid2, centroid3 = centroids[0], centroids[1], centroids[2]\n",
    "    \n",
    "    for iteration in range(2):\n",
    "        # your code here\n",
    "        \n",
    "        current_centroids = [centroid1, centroid2, centroid3]\n",
    "        #Assign each point to cluster\n",
    "        for point in dataset:\n",
    "            this_assignment = cluster_assignment(current_centroids, point)\n",
    "            result[str(iteration + 1)][this_assignment].append(point)\n",
    "        \n",
    "        #Update centroids\n",
    "        for cluster in list(result[str(iteration + 1)].keys())[0:3]:\n",
    "            xvals = []\n",
    "            yvals = []\n",
    "            \n",
    "            for point in result[str(iteration + 1)][cluster]:\n",
    "                xvals.append(point[0])\n",
    "                yvals.append(point[1])\n",
    "            \n",
    "            new_centroid_x = np.mean(xvals)\n",
    "            new_centroid_y = np.mean(yvals)\n",
    "            \n",
    "            result[str(iteration + 1)][\"centroids\"].append([new_centroid_x, new_centroid_y])\n",
    "        \n",
    "        #Tell next loop what the centroids are\n",
    "        centroid1 = result[str(iteration + 1)][\"centroids\"][0]\n",
    "        centroid2 = result[str(iteration + 1)][\"centroids\"][1]\n",
    "        centroid3 = result[str(iteration + 1)][\"centroids\"][2]\n",
    "        \n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'cluster1': [[23, 96], [29, 99], [30, 64], [12, 68]],\n",
       "  'cluster2': [[46, 33], [82, 20], [57, 51], [25, 9]],\n",
       "  'cluster3': [[26, 21], [25, 42]],\n",
       "  'centroids': [[23.5, 81.75], [52.5, 28.25], [25.5, 31.5]]},\n",
       " '2': {'cluster1': [[23, 96], [29, 99], [30, 64], [12, 68]],\n",
       "  'cluster2': [[46, 33], [82, 20], [57, 51]],\n",
       "  'cluster3': [[26, 21], [25, 42], [25, 9]],\n",
       "  'centroids': [[23.5, 81.75],\n",
       "   [61.666666666666664, 34.666666666666664],\n",
       "   [25.333333333333332, 24.0]]}}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means_clustering(test_centroids, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ce4d9047099ccf8168168ba26674db4",
     "grade": true,
     "grade_id": "cell-6beada533a0abe0c",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# This cell has hidden test cases that will run after you submit your assignment. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb3740b06d0eeb71a34c67ee39cb3d47",
     "grade": false,
     "grade_id": "cell-be657f959b985aa4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [10 points] Problem 2 - Clustering using EM Method\n",
    "***\n",
    "\n",
    "A sample dataset has been provided to you in the './data/sample_dataset_em.pickle' path. The centroids are in './data/sample_centroids_em.pickle' and the sample result is in './data/sample_result_em.pickle' path. You can use these to test your code. \n",
    "\n",
    "Here are the attributes for the dataset. Use this dataset to test your functions.\n",
    "\n",
    "- Dataset should load the points in the form of a list of lists where each list item represents a point in the space. \n",
    "- An example dataset will have the following structure. If there are 3 points in the dataset, this would appear as follows in the list of lists.\n",
    "\n",
    "```python\n",
    "dataset = [5,7,9]\n",
    "  \n",
    "```\n",
    "\n",
    "Note:\n",
    "- A sample dataset to test your code has been provided in the location \"data/em_dataset.pickle\". Please maintain this as it would be necessary while grading.\n",
    "- Do not change the variable names of the returned values.\n",
    "- After calculating each of those values, assign them to the corresponding value that is being returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06b2ebdf9fe997a517e90328aeb305ef",
     "grade": false,
     "grade_id": "cell-00eeb28b483d10a8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def prob_obs_given_centroid(observation, centroid):\n",
    "    \"\"\"\n",
    "        Helper function for prob_centroid_given_obs\n",
    "        Input: float observation, list of floats [mu, sd] centroid\n",
    "        Output: float probability in [0, 1]\n",
    "    \"\"\"\n",
    "    # Assumes that centroids are Gaussian distributions of form [mu, sd]\n",
    "    mu_j = centroid[0]\n",
    "    sd_j = centroid[1]\n",
    "    \n",
    "    prob_obs_centroid = (1 / (sd_j * np.sqrt(2 * np.pi))) * math.exp((-1/2) * ((observation - mu_j)/sd_j)**2)\n",
    "    \n",
    "    return(prob_obs_centroid)\n",
    "\n",
    "def prob_centroid_j_given_obs(observation, centroids, j):\n",
    "    \"\"\"\n",
    "        Helper function for em_clustering\n",
    "        Input: float observation, list of list of floats [mu, sd] centroids, integer j \n",
    "        Output: float probability in [0, 1]\n",
    "    \"\"\"\n",
    "    # Assumes that centroids are Gaussian distributions of form [mu, sd]\n",
    "    probs_obs_given_centroids = []\n",
    "    for centroid in centroids:\n",
    "        this_prob = prob_obs_given_centroid(observation, centroid)\n",
    "        probs_obs_given_centroids.append(this_prob)\n",
    "        \n",
    "    numerator = probs_obs_given_centroids[j]\n",
    "    denominator = np.sum(probs_obs_given_centroids)\n",
    "    \n",
    "    prob_centroid_j_obs = numerator / denominator\n",
    "    \n",
    "    return(prob_centroid_j_obs)\n",
    "\n",
    "def em_clustering(centroids, dataset):\n",
    "\n",
    "#   Input: \n",
    "#       1. centroids - A list of lists with each value representing the mean and standard deviation values picked from a gausian distribution.\n",
    "#       2. dataset - A list of points randomly picked.\n",
    "#   Output:\n",
    "#       1. results - Return the updated centroids(updated mean and std values after the EM step) after the first iteration.\n",
    "\n",
    "    new_centroids = list()\n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "    \n",
    "    for j in range(len(centroids)):\n",
    "        #Fill out prob_j_given_oi\n",
    "        prob_j_given_oi = []\n",
    "        \n",
    "        for obs in dataset:\n",
    "            current_prob = prob_centroid_j_given_obs(obs, centroids, j)\n",
    "            prob_j_given_oi.append(current_prob)\n",
    "            \n",
    "        #Determine new mean and sd for centroid j\n",
    "        normalization_constant = np.sum(prob_j_given_oi)\n",
    "        \n",
    "        mu_list_to_sum = []\n",
    "        for i in range(len(dataset)):\n",
    "            mu_list_to_sum.append(dataset[i] * prob_j_given_oi[i])\n",
    "        \n",
    "        mu_j = np.sum(mu_list_to_sum)  / normalization_constant\n",
    "        \n",
    "        var_list_to_sum = []\n",
    "        for i in range(len(dataset)):\n",
    "            var_list_to_sum.append((dataset[i] - mu_j)**2 * prob_j_given_oi[i])\n",
    "        \n",
    "        var_j = np.sum(var_list_to_sum) / normalization_constant\n",
    "        sd_j = np.sqrt(var_j)\n",
    "        new_centroids.append([mu_j, sd_j])\n",
    "\n",
    "    return new_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[13.346550530668155, 3.236599802533008],\n",
       " [7.9971108077796735, 4.473417525043109]]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_clustering(centroids_em, data_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13, 2], [2, 16]]\n",
      "[8, 16, 13, 9, 18, 15, 7, 5, 7, 3]\n",
      "[[13.346550530668159, 3.236599802533008], [7.9971108077796735, 4.473417525043109]]\n"
     ]
    }
   ],
   "source": [
    "path_centroids_em = './data/sample_centroids_em.pickle'\n",
    "path_data_em =  './data/sample_dataset_em.pickle'\n",
    "path_results_em = \"./data/sample_result_em.pickle\"\n",
    "\n",
    "centroids_file_em = open(path_centroids_em, \"rb\")\n",
    "centroids_em = pickle.load(centroids_file_em)\n",
    "centroids_file_em.close()\n",
    "print(centroids_em)\n",
    "\n",
    "data_file_em = open(path_data_em, \"rb\")\n",
    "data_em = pickle.load(data_file_em)\n",
    "data_file_em.close()\n",
    "print(data_em)\n",
    "\n",
    "result_file_em = open(path_results_em, \"rb\")\n",
    "results_em = pickle.load(result_file_em)\n",
    "result_file_em.close()\n",
    "print(results_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_clustering(centroids_em, data_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bae4639b485c93815a591805beefb4df",
     "grade": true,
     "grade_id": "cell-475bb00465b45bcc",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# This cell has hidden test cases that will run after you submit your assignment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
